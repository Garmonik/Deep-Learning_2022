# -*- coding: utf-8 -*-
"""baseline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h6-kidtbCh6c99Ew2c43moRJbOrxmzSR

<p style="align: center;"><img align=center src="https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg" width=500 height=450/></p>

<h3 style="text-align: center;"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>

<h3 style="text-align: center;"><b>Домашнее задание. Продвинутый поток. Весна 2021</b></h3>

Это домашнее задание будет посвящено полноценному решению задачи машинного обучения.

Есть две части этого домашнего задания: 
* Сделать полноценный отчет о вашей работе: как вы обработали данные, какие модели попробовали и какие результаты получились (максимум 10 баллов). За каждую выполненную часть будет начислено определенное количество баллов.
* Лучшее решение отправить в соревнование на [kaggle](https://www.kaggle.com/c/advanced-dls-spring-2021/) (максимум 5 баллов). За прохождение определенного порогов будут начисляться баллы.


**Обе части будут проверяться в формате peer-review. Т.е. вашу посылку на степик будут проверять несколько других студентов и аггрегация их оценок будет выставлена. В то же время вам тоже нужно будет проверить несколько других учеников.**

**Пожалуйста, делайте свою работу чистой и понятной, чтобы облегчить проверку. Если у вас будут проблемы с решением или хочется совета, то пишите в наш чат в телеграме или в лс @runfme. Если вы захотите проаппелировать оценку, то пипшите в лс @runfme.**

**Во всех пунктах указания это минимальный набор вещей, которые стоит сделать. Если вы можете сделать какой-то шаг лучше или добавить что-то свое - дерзайте!**

# Как проверять?

Ставьте полный балл, если выполнены все рекомендации или сделано что-то более интересное и сложное. За каждый отсустствующий пункт из рекомендация снижайте 1 балл.

# Метрика

Перед решением любой задачи важно понимать, как будет оцениваться ваше решение. В данном случае мы используем стандартную для задачи классификации метрику ROC-AUC. Ее можно вычислить используя только предсказанные вероятности и истинные классы без конкретного порога классификации + она раотает даже если классы в данных сильно несбалансированны (примеров одного класса в десятки раз больше примеров длугого). Именно поэтому она очень удобна для соревнований.

Посчитать ее легко:
"""

from sklearn.metrics import roc_auc_score

y_true = [
    0,
    1,
    1,
    0,
    1
]

y_predictions = [
    0.1,
    0.9,
    0.4,
    0.6,
    0.61
]

roc_auc_score(y_true, y_predictions)

"""# Первая часть. Исследование"""

!pip install catboost
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt

"""## Загрузка данных (2 балла)

1) Посмотрите на случайные строчки. 

2) Посмотрите, есть ли в датасете незаполненные значения (nan'ы) с помощью data.isna() или data.info() и, если нужно, замените их на что-то. Будет хорошо, если вы построите табличку с количеством nan в каждой колонке.
"""

data_train = pd.read_csv('./train.csv')
data_test = pd.read_csv('./test.csv')

# Для вашего удобства списки с именами разных колонок

# Числовые признаки
num_cols = [
    'ClientPeriod',
    'MonthlySpending',
    'TotalSpent'
]

# Категориальные признаки
cat_cols = [
    'Sex',
    'IsSeniorCitizen',
    'HasPartner',
    'HasChild',
    'HasPhoneService',
    'HasMultiplePhoneNumbers',
    'HasInternetService',
    'HasOnlineSecurityService',
    'HasOnlineBackup',
    'HasDeviceProtection',
    'HasTechSupportAccess',
    'HasOnlineTV',
    'HasMovieSubscription',
    'HasContractPhone',
    'IsBillingPaperless',
    'PaymentMethod'
]

feature_cols = num_cols + cat_cols
target_col = 'Churn'

"""# **Анализ**"""

data_train.head()

data_test.head()

data_train.dtypes

data_test.dtypes

data_test['TotalSpent'] = pd.to_numeric(data_test['TotalSpent'], errors='coerce')
data_train['TotalSpent'] = pd.to_numeric(data_train['TotalSpent'], errors='coerce')
test_cat_features = cat_cols.copy()
cat_cols.append(target_col)
train_cat_features = cat_cols

print(train_cat_features)

data_train[train_cat_features] = data_train[train_cat_features].astype('category')
data_test[test_cat_features] = data_test[test_cat_features].astype('category')
data_test.dtypes

data_train.dtypes

"""# **Удаление**"""

data_train.isna().mean().sort_values(ascending=False)

data_test.isna().mean().sort_values(ascending=False)

data_test['TotalSpent'] = data_test.TotalSpent.fillna(0)
print(pd.isnull(data_test.TotalSpent))

data_train['TotalSpent'] = data_train.TotalSpent.fillna(0)
print(pd.isnull(data_train.TotalSpent))

data_train = data_train.dropna()
data_test = data_test.dropna()

"""## Анализ данных (3 балла)

1) Для численных призанков постройте гистограмму (*plt.hist(...)*) или boxplot (*plt.boxplot(...)*). Для категориальных посчитайте количество каждого значения для каждого признака. Для каждой колонки надо сделать *data.value_counts()* и построить bar диаграммы *plt.bar(...)* или круговые диаграммы *plt.pie(...)* (хорошо, елси вы сможете это сделать на одном гарфике с помощью *plt.subplots(...)*). 

2) Посмотрите на распределение целевой переменной и скажите, являются ли классы несбалансированными.

3) (Если будет желание) Поиграйте с разными библиотеками для визуализации - *sns*, *pandas_visual_analysis*, etc.

Второй пункт очень важен, потому что существуют задачи классификации с несбалансированными классами. Например, это может значить, что в датасете намного больше примеров 0 класса. В таких случаях нужно 1) не использовать accuracy как метрику 2) использовать методы борьбы с imbalanced dataset (обычно если датасет сильно несбалансирован, т.е. класса 1 в 20 раз меньше класса 0).

# **Численные данные**
"""

plt.hist(data_train[num_cols[0]])

plt.boxplot(data_train[num_cols[0]])

plt.hist(data_train[num_cols[1]])

plt.boxplot(data_train[num_cols[1]])

plt.hist(data_train[num_cols[2]])

plt.boxplot(data_train[num_cols[2]])

"""# **Категориальные признаки**"""

for cat in train_cat_features:
  print(cat, data_train[cat].value_counts(),'\n', sep='\n')

"""(Дополнительно) Если вы нашли какие-то ошибки в данных или выбросы, то можете их убрать. Тут можно поэксперементировать с обработкой данных как угодно, но не за баллы."""

fig, axs = plt.subplots(1, len(cat_cols))
for i in range(len(train_cat_features)):
    print(data_train[train_cat_features[i]].value_counts())
    axs[i].pie(data_train[cat_cols[i]].value_counts(), radius=1)

plt.pie(data_train[target_col].value_counts(), radius=1)

for i in range(len(train_cat_features)):
    plt.hist(data_train[train_cat_features[i]])
    plt.show()
    print(train_cat_features[i])

"""Классы несбалансированны!

## Применение линейных моделей (3 балла)

1) Обработайте данные для того, чтобы к ним можно было применить LogisticRegression. Т.е. отнормируйте числовые признаки, а категориальные закодируйте с помощью one-hot-encoding'а. 

2) С помощью кроссвалидации или разделения на train/valid выборку протестируйте разные значения гиперпараметра C и выберите лучший (можно тестировать С=100, 10, 1, 0.1, 0.01, 0.001) по метрике ROC-AUC. 

Если вы разделяете на train/valid, то используйте LogisticRegressionCV. Он сам при вызове .fit() подберет параметр С. (не забудьте передать scroing='roc_auc', чтобы при кроссвалидации сравнивались значения этой метрики, и refit=True, чтобы при потом модель обучилась на всем датасете с лучшим параметром C). 


(более сложный вариант) Если вы будете использовать кроссвалидацию, то преобразования данных и LogisticRegression нужно соединить в один Pipeline с помощью make_pipeline, как это делалось во втором семинаре. Потом pipeline надо передать в GridSearchCV. Для one-hot-encoding'a можно испльзовать комбинацию LabelEncoder + OneHotEncoder (сначала превращаем строчки в числа, а потом числа првращаем в one-hot вектора.)

# **Нурмировка**
"""

from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder
from sklearn.pipeline import make_pipeline

data_cat = data_train.drop(columns=['ClientPeriod', 'MonthlySpending', 'TotalSpent', 'Churn'])
data_test_cat = data_test.drop(columns=['ClientPeriod', 'MonthlySpending', 'TotalSpent'])
data_cat.head()

train_small_with_dummies = pd.get_dummies(data_cat, sparse=True)
test_small_with_dummies = pd.get_dummies(data_test_cat, sparse=True)
train_small_with_dummies.head(100)

data_num = data_train[['ClientPeriod', 'MonthlySpending', 'TotalSpent']]
data_test_num = data_test[['ClientPeriod', 'MonthlySpending', 'TotalSpent']]
data_num.head(100)

normalized_data_num = (data_num-data_num.min())/(data_num.max()-data_num.min())
normalized_data_test_num = (data_test_num-data_test_num.min())/(data_test_num.max()-data_test_num.min())
normalized_data_num.head(100)

X = pd.concat([train_small_with_dummies, normalized_data_num], axis=1)
X_test = pd.concat([test_small_with_dummies, normalized_data_test_num], axis=1)
X.head(100)

len(X_test)

y = data_train['Churn']
y.head()

"""# **Применение линейной регрессии**"""

from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score

clf = LogisticRegressionCV(cv=5, random_state=42, scoring='roc_auc', n_jobs=-1, refit=True).fit(X, y)

clf.predict(X)

y

scores = cross_val_score(clf, X, y, cv=5, scoring='roc_auc')
print(scores)

"""# **[0.86228825 0.83692956 0.83457358 0.8561008  0.83573312]**"""

print(scores.mean())

"""# **0.8451250628424853**

Выпишите какое лучшее качество и с какими параметрами вам удалось получить

## Применение градиентного бустинга (2 балла)

Если вы хотите получить баллы за точный ответ, то стоит попробовать градиентный бустинг. Часто градиентный бустинг с дефолтными параметрами даст вам 80% результата за 0% усилий.

Мы будем использовать catboost, поэтому нам не надо кодировать категориальные признаки. catboost сделает это сам (в .fit() надо передать cat_features=cat_cols). А численные признаки нормировать для моделей, основанных на деревьях не нужно.

1) Разделите выборку на train/valid. Протестируйте catboost cо стандартными параметрами.

2) Протестируйте разные занчения параметроа количества деревьев и learning_rate'а и выберите лучшую по метрике ROC-AUC комбинацию. 

(Дополнительно) Есть некоторые сложности с тем, чтобы использовать CatBoostClassifier вместе с GridSearchCV, поэтому мы не просим использовать кроссвалидацию. Но можете попробовать)
"""

train, test = train_test_split(data_train,train_size=0.6,random_state=42,stratify=data_train['Churn'])
val, test = train_test_split(test,train_size=0.5,random_state=42,stratify=test['Churn'])
y = ['Churn']

from catboost.core import Pool
train_data = Pool(data=train[X],
                  label=train[y],
                  cat_features=test_cat_features
                  )

valid_data = Pool(data=val[X],
                  label=val[y],
                  cat_features=test_cat_features
                  )

params = {'verbose':100,
          'random_seed':42,
          'eval_metric':'AUC',
          'learning_rate':0.09}

from catboost import CatBoostClassifier

model_cat_default = CatBoostClassifier(**params)

model_cat_default.fit(train_data,eval_set=valid_data)

test['churn_cat_default'] = model_cat_default.predict_proba(test[X])[:,1]
test_score = roc_auc_score(test['Churn'], test['churn_cat_default'])
print(test_score)

"""Выпишите какое лучшее качество и с какими параметрами вам удалось получить

# Предсказания
"""

best_model = model_cat_default # какая-то предыдущая модель

X_test = pd.read_csv('./test.csv')
submission = pd.read_csv('./submission.csv')

submission['Churn'] = best_model.predict_proba(X_test)[:,1]
submission.to_csv('./my_submission.csv', index=False)
submission = pd.read_csv('./my_submission.csv')
print(submission)

"""# **bestTest = 0.8491540112**
# **bestIteration = 98**

# Kaggle (5 баллов)

Как выставить баллы:

1) 1 >= roc auc > 0.84 это 5 баллов

2) 0.84 >= roc auc > 0.7 это 3 балла

3) 0.7 >= roc auc > 0.6 это 1 балл

4) 0.6 >= roc auc это 0 баллов


Для выполнения задания необходимо выполнить следующие шаги.
* Зарегистрироваться на платформе [kaggle.com](kaggle.com). Процесс выставления оценок будет проходить при подведении итогового рейтинга. Пожалуйста, укажите во вкладке Team -> Team name свои имя и фамилию в формате Имя_Фамилия (важно, чтобы имя и фамилия совпадали с данными на Stepik).
* Обучить модель, получить файл с ответами в формате .csv и сдать его в конкурс. Пробуйте и экспериментируйте. Обратите внимание, что вы можете выполнять до 20 попыток сдачи на kaggle в день.
* После окончания соревнования отправить в итоговый ноутбук с решением на степик. 
* После дедлайна проверьте посылки других участников по критериям. Для этого надо зайти на степик, скачать их ноутбук и проверить скор в соревновании.
"""